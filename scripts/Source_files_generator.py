# -*- coding: utf-8 -*-
"""Azure.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wM3M2n8uuC9gMrajObX7kj7wqFBCFOmq
"""

!pip install azure.storage.blob

"""**GENERATE INVENTORY AND SALESORDER CSV FILES**"""

import os

import pandas as pd
import random
from datetime import datetime, timedelta
import json

# ------------------------------------
# PARAMETERS
# ------------------------------------
warehouses = {
    "WH1": "Mumbai",
    "WH2": "Delhi",
    "WH3": "Bangalore",
    "WH4": "Chennai",
    "WH5": "Hyderabad"
}

products_catalog = [
    ("Laptop Bag", "Accessories"),
    ("Bluetooth Mouse", "Electronics"),
    ("Mechanical Keyboard", "Electronics"),
    ("Office Chair", "Furniture"),
    ("Standing Desk", "Furniture"),
    ("Inkjet Printer", "Electronics"),
    ("Wireless Headphones", "Electronics"),
    ("LED Desk Lamp", "Lighting"),
    ("Filing Cabinet", "Office Supplies"),
    ("Projector", "Electronics"),
    ("Coffee Machine", "Appliances"),
    ("Whiteboard", "Stationery"),
    ("Air Purifier", "Appliances"),
    ("Smartphone Stand", "Accessories"),
    ("Portable Hard Drive", "Electronics"),
    ("Conference Speakerphone", "Electronics"),
    ("Wall Clock", "Decor"),
    ("Floor Mat", "Furniture"),
    ("USB-C Hub", "Electronics"),
    ("Surge Protector", "Electronics")
]

sales_order_count = 5000
shipment_event_count = 1500
products_per_warehouse = 100  # 100 x 5 warehouses = 500 rows

# ------------------------------------
# INVENTORY DATA (500 rows)
# ------------------------------------
inventory_data = []
pid_counter = 1

for wh_id, wh_city in warehouses.items():
    for _ in range(products_per_warehouse):
        product_name, category = random.choice(products_catalog)
        pid = f"PRD{pid_counter:04d}"
        quantity_in_stock = random.randint(5, 500)
        last_restock_date = datetime(2025, 7, 1) + timedelta(days=random.randint(0, 30))
        inventory_data.append([
            wh_id, pid, product_name, category,
            quantity_in_stock, last_restock_date.strftime("%Y-%m-%d")
        ])
        pid_counter += 1

inventory_df = pd.DataFrame(inventory_data, columns=[
    "warehouse_id", "product_id", "product_name", "category",
    "quantity_in_stock", "last_restock_date"
])

# ------------------------------------
# SALES ORDERS DATA (5000 rows)
# ------------------------------------
sales_orders = []
for i in range(1, sales_order_count + 1):
    product = inventory_df.sample(1).iloc[0]
    order_id = f"ORD{i:05d}"
    quantity_sold = random.randint(1, 20)
    sale_date = datetime(2025, 7, 1) + timedelta(days=random.randint(0, 30))
    sales_orders.append([
        order_id, product["product_id"], quantity_sold,
        sale_date.strftime("%Y-%m-%d"), product["warehouse_id"]
    ])

sales_orders_df = pd.DataFrame(sales_orders, columns=[
    "order_id", "product_id", "quantity_sold", "sale_date", "warehouse_id"
])

# ------------------------------------
# STREAMING SHIPMENT EVENTS (1500 rows)
# ------------------------------------
statuses = ["In Transit", "Delivered", "Delayed"]
delay_reasons = ["Traffic", "Weather", "Technical Issue"]
locations = list(warehouses.values())
start_time = datetime(2025, 8, 12, 10, 25)

shipments = []
for i in range(1, shipment_event_count + 1):
    wh_id, wh_city = random.choice(list(warehouses.items()))
    status = random.choices(statuses, weights=[0.5, 0.3, 0.2])[0]
    shipment = {
        "shipment_id": f"SH{100000+i}",
        "warehouse_id": wh_id,
        "status": status,
        "location": wh_city if random.random() < 0.8 else f"{random.uniform(12, 28):.4f},{random.uniform(72, 88):.4f}",
        "timestamp": (start_time + timedelta(minutes=i)).strftime("%Y-%m-%dT%H:%M:%SZ")
    }
    if status == "Delayed":
        shipment["delay_reason"] = random.choice(delay_reasons)
    shipments.append(shipment)

# ------------------------------------
# SAVE FILES
# ------------------------------------
inventory_df.to_csv("/content/drive/MyDrive/SwiftSupplyLogistics/Batch/Raw/inventory_20250831.csv", index=False)
sales_orders_df.to_csv("/content/drive/MyDrive/SwiftSupplyLogistics/Batch/Raw/sales_orders_20250831.csv", index=False)
'''with open("shipments_1500.json", "w") as f:
    json.dump(shipments, f, indent=2)
'''
print("✅ Files created: inventory_500.csv, sales_orders_5000.csv, shipments_1500.json")

inventory_df

"""**GENERATE SHIPMENTS JSON FILES**"""

import json
import random
import time
from datetime import datetime
from azure.storage.blob import BlobServiceClient

# ---------------------------
# ADLS / Azure Blob Config
# ---------------------------
STORAGE_ACCOUNT_URL = "https://datalakessl.blob.core.windows.net"
STORAGE_ACCOUNT_KEY = "UTGefz+sBOqpKrWJjTwd7QavthKbEYASJ9DzZyzNB7mfuHCM2GjvszK1ReYeTFuxQBiHzsyPTscE+AStxgihCA=="
CONTAINER_NAME = "ssl-bronze"  # Your ADLS container

# ---------------------------
# Business Data Config
# ---------------------------
warehouses = {
    "WH1": "Mumbai",
    "WH2": "Delhi",
    "WH3": "Bangalore",
    "WH4": "Chennai",
    "WH5": "Hyderabad"
}

statuses = ["In Transit", "Delivered", "Delayed"]
delay_reasons = ["Traffic", "Weather", "Technical Issue"]

# ---------------------------
# Azure Blob Client
# ---------------------------
blob_service_client = BlobServiceClient(account_url=STORAGE_ACCOUNT_URL, credential=STORAGE_ACCOUNT_KEY)
container_client = blob_service_client.get_container_client(CONTAINER_NAME)

# ---------------------------
# Event Generator Function
# ---------------------------
def generate_shipment_event(event_id):
    wh_id, wh_city = random.choice(list(warehouses.items()))
    status = random.choices(statuses, weights=[0.5, 0.3, 0.2])[0]

    event = {
        "shipment_id": f"SH{100000+event_id}",
        "warehouse_id": wh_id,
        "status": status,
        "location": wh_city if random.random() < 0.8 else f"{random.uniform(12, 28):.4f},{random.uniform(72, 88):.4f}",
        "timestamp": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
    }

    if status == "Delayed":
        event["delay_reason"] = random.choice(delay_reasons)

    return event

# ---------------------------
# Main Loop — Send Events to ADLS
# ---------------------------
def send_events_to_adls(event_count=100, delay_seconds=2):
    for i in range(event_count):
        event = generate_shipment_event(i+1)
        event_json = json.dumps(event, indent=2)

        # Create blob name with folder by date
        blob_name = f"streaming/landing_shipments/{datetime.utcnow().strftime('%Y%m%d')}/shipment_{event['shipment_id']}_{datetime.utcnow().strftime('%Y_%m_%d_%H%M%S')}.json"

        # Upload JSON directly to ADLS container
        container_client.upload_blob(name=blob_name, data=event_json, overwrite=True)

        print(f"✅ Sent: {event['shipment_id']} → {blob_name}")
        time.sleep(delay_seconds)  # Simulate real-time

# ---------------------------
# Run
# ---------------------------
if __name__ == "__main__":
    send_events_to_adls(event_count=250, delay_seconds=0)  # Send events quickly

